{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adabc1b6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.005311,
     "end_time": "2022-06-09T09:37:31.763740",
     "exception": false,
     "start_time": "2022-06-09T09:37:31.758429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keras Quickstart for the AMEX Competition: Training and Inference\n",
    "\n",
    "This notebook shows\n",
    "- how to do space-efficient feature engineering\n",
    "- how to implement a simple Keras model\n",
    "- how to train and cross-validate the model\n",
    "- how to understand the competition metric graphically\n",
    "\n",
    "The notebook is based on insights of the [EDA which makes sense ⭐️⭐️⭐️⭐️⭐️](https://www.kaggle.com/code/ambrosm/amex-eda-which-makes-sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d276d9",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-09T09:37:31.776853Z",
     "iopub.status.busy": "2022-06-09T09:37:31.776130Z",
     "iopub.status.idle": "2022-06-09T09:37:39.324234Z",
     "shell.execute_reply": "2022-06-09T09:37:39.323180Z"
    },
    "papermill": {
     "duration": 7.556174,
     "end_time": "2022-06-09T09:37:39.326767",
     "exception": false,
     "start_time": "2022-06-09T09:37:31.770593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import datetime\n",
    "import math\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from colorama import Fore, Back, Style\n",
    "import gc\n",
    "import os\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer, Add, Concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "INFERENCE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d61bd1",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-09T09:37:39.337308Z",
     "iopub.status.busy": "2022-06-09T09:37:39.336688Z",
     "iopub.status.idle": "2022-06-09T09:37:39.350444Z",
     "shell.execute_reply": "2022-06-09T09:37:39.349432Z"
    },
    "papermill": {
     "duration": 0.021503,
     "end_time": "2022-06-09T09:37:39.352628",
     "exception": false,
     "start_time": "2022-06-09T09:37:39.331125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_history(history, *, n_epochs=None, plot_lr=False, title=None, bottom=None, top=None):\n",
    "    \"\"\"Plot (the last n_epochs epochs of) the training history\n",
    "    \n",
    "    Plots loss and optionally val_loss and lr.\"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    from_epoch = 0 if n_epochs is None else max(len(history['loss']) - n_epochs, 0)\n",
    "    \n",
    "    # Plot training and validation losses\n",
    "    plt.plot(np.arange(from_epoch, len(history['loss'])), history['loss'][from_epoch:], label='Training loss')\n",
    "    try:\n",
    "        plt.plot(np.arange(from_epoch, len(history['loss'])), history['val_loss'][from_epoch:], label='Validation loss')\n",
    "        best_epoch = np.argmin(np.array(history['val_loss']))\n",
    "        best_val_loss = history['val_loss'][best_epoch]\n",
    "        if best_epoch >= from_epoch:\n",
    "            plt.scatter([best_epoch], [best_val_loss], c='r', label=f'Best val_loss = {best_val_loss:.5f}')\n",
    "        if best_epoch > 0:\n",
    "            almost_epoch = np.argmin(np.array(history['val_loss'])[:best_epoch])\n",
    "            almost_val_loss = history['val_loss'][almost_epoch]\n",
    "            if almost_epoch >= from_epoch:\n",
    "                plt.scatter([almost_epoch], [almost_val_loss], c='orange', label='Second best val_loss')\n",
    "    except KeyError:\n",
    "        pass\n",
    "    if bottom is not None: plt.ylim(bottom=bottom)\n",
    "    if top is not None: plt.ylim(top=top)\n",
    "    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='lower left')\n",
    "    if title is not None: plt.title(title)\n",
    "        \n",
    "    # Plot learning rate\n",
    "    if plot_lr and 'lr' in history:\n",
    "        ax2 = plt.gca().twinx()\n",
    "        ax2.plot(np.arange(from_epoch, len(history['lr'])), np.array(history['lr'][from_epoch:]), color='g', label='Learning rate')\n",
    "        ax2.set_ylabel('Learning rate')\n",
    "        ax2.legend(loc='upper right')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ecc71a",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-09T09:37:39.363274Z",
     "iopub.status.busy": "2022-06-09T09:37:39.362876Z",
     "iopub.status.idle": "2022-06-09T09:37:39.375594Z",
     "shell.execute_reply": "2022-06-09T09:37:39.374305Z"
    },
    "papermill": {
     "duration": 0.020559,
     "end_time": "2022-06-09T09:37:39.377709",
     "exception": false,
     "start_time": "2022-06-09T09:37:39.357150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/code/inversion/amex-competition-metric-python\n",
    "def amex_metric(y_true, y_pred, return_components=False) -> float:\n",
    "    \"\"\"Amex metric for ndarrays\"\"\"\n",
    "    def top_four_percent_captured(df) -> float:\n",
    "        \"\"\"Corresponds to the recall for a threshold of 4 %\"\"\"\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(df) -> float:\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(df) -> float:\n",
    "        \"\"\"Corresponds to 2 * AUC - 1\"\"\"\n",
    "        df2 = pd.DataFrame({'target': df.target, 'prediction': df.target})\n",
    "        df2.sort_values('prediction', ascending=False, inplace=True)\n",
    "        return weighted_gini(df) / weighted_gini(df2)\n",
    "\n",
    "    df = pd.DataFrame({'target': y_true.ravel(), 'prediction': y_pred.ravel()})\n",
    "    df.sort_values('prediction', ascending=False, inplace=True)\n",
    "    g = normalized_weighted_gini(df)\n",
    "    d = top_four_percent_captured(df)\n",
    "\n",
    "    if return_components: return g, d, 0.5 * (g + d)\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d65edb",
   "metadata": {
    "papermill": {
     "duration": 0.004271,
     "end_time": "2022-06-09T09:37:39.386444",
     "exception": false,
     "start_time": "2022-06-09T09:37:39.382173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading and preprocessing the training data\n",
    "\n",
    "We read the data from @raddar's [dataset](https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format). @raddar has [denoised the data](https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514) so that we can achieve better results with his dataset than with the original competition csv files.\n",
    "\n",
    "Then we create several groups of features:\n",
    "- Selected features averaged over all statements of a customer\n",
    "- Minimum / maximum of selected features over all statements of a customer\n",
    "- Selected features taken from the last statement of a customer\n",
    "\n",
    "We one-hot encode the categorical features and fill all missing values with 0.\n",
    "\n",
    "The code has been optimized for memory efficiency rather than readability. In particular, `.iloc[mask_array, columns]` needs much less RAM than the groupby construction used in previous versions of the notebook. Deleting the index of the train dataframe frees another 0.2 GByte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db764319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:37:39.398081Z",
     "iopub.status.busy": "2022-06-09T09:37:39.397308Z",
     "iopub.status.idle": "2022-06-09T09:44:14.595405Z",
     "shell.execute_reply": "2022-06-09T09:44:14.594279Z"
    },
    "papermill": {
     "duration": 395.206502,
     "end_time": "2022-06-09T09:44:14.597825",
     "exception": false,
     "start_time": "2022-06-09T09:37:39.391323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "features_avg = ['B_11', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_2', \n",
    "                'B_20', 'B_28', 'B_29', 'B_3', 'B_33', 'B_36', 'B_37', 'B_4', 'B_42', \n",
    "                'B_5', 'B_8', 'B_9', 'D_102', 'D_103', 'D_105', 'D_111', 'D_112', 'D_113', \n",
    "                'D_115', 'D_118', 'D_119', 'D_121', 'D_124', 'D_128', 'D_129', 'D_131', \n",
    "                'D_132', 'D_133', 'D_139', 'D_140', 'D_141', 'D_143', 'D_144', 'D_145', \n",
    "                'D_39', 'D_41', 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', \n",
    "                'D_49', 'D_50', 'D_51', 'D_52', 'D_56', 'D_58', 'D_62', 'D_70', 'D_71', \n",
    "                'D_72', 'D_74', 'D_75', 'D_79', 'D_81', 'D_83', 'D_84', 'D_88', 'D_91', \n",
    "                'P_2', 'P_3', 'R_1', 'R_10', 'R_11', 'R_13', 'R_18', 'R_19', 'R_2', 'R_26', \n",
    "                'R_27', 'R_28', 'R_3', 'S_11', 'S_12', 'S_22', 'S_23', 'S_24', 'S_26', \n",
    "                'S_27', 'S_5', 'S_7', 'S_8', ]\n",
    "features_min = ['B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_19', 'B_2', 'B_20', 'B_22', \n",
    "                'B_24', 'B_27', 'B_28', 'B_29', 'B_3', 'B_33', 'B_36', 'B_4', 'B_42', \n",
    "                'B_5', 'B_9', 'D_102', 'D_103', 'D_107', 'D_109', 'D_110', 'D_111', \n",
    "                'D_112', 'D_113', 'D_115', 'D_118', 'D_119', 'D_121', 'D_122', 'D_128', \n",
    "                'D_129', 'D_132', 'D_133', 'D_139', 'D_140', 'D_141', 'D_143', 'D_144', \n",
    "                'D_145', 'D_39', 'D_41', 'D_42', 'D_45', 'D_46', 'D_48', 'D_50', 'D_51', \n",
    "                'D_53', 'D_54', 'D_55', 'D_56', 'D_58', 'D_59', 'D_60', 'D_62', 'D_70', \n",
    "                'D_71', 'D_74', 'D_75', 'D_78', 'D_79', 'D_81', 'D_83', 'D_84', 'D_86', \n",
    "                'D_88', 'D_96', 'P_2', 'P_3', 'P_4', 'R_1', 'R_11', 'R_13', 'R_17', 'R_19', \n",
    "                'R_2', 'R_27', 'R_28', 'R_4', 'R_5', 'R_8', 'S_11', 'S_12', 'S_23', 'S_25', \n",
    "                'S_3', 'S_5', 'S_7', 'S_9', ]\n",
    "features_max = ['B_1', 'B_11', 'B_13', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_2', \n",
    "                'B_22', 'B_24', 'B_27', 'B_28', 'B_29', 'B_3', 'B_31', 'B_33', 'B_36', \n",
    "                'B_4', 'B_42', 'B_5', 'B_7', 'B_9', 'D_102', 'D_103', 'D_105', 'D_109', \n",
    "                'D_110', 'D_112', 'D_113', 'D_115', 'D_121', 'D_124', 'D_128', 'D_129', \n",
    "                'D_131', 'D_139', 'D_141', 'D_144', 'D_145', 'D_39', 'D_41', 'D_42', \n",
    "                'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_50', 'D_51', 'D_52', \n",
    "                'D_53', 'D_56', 'D_58', 'D_59', 'D_60', 'D_62', 'D_70', 'D_72', 'D_74', \n",
    "                'D_75', 'D_79', 'D_81', 'D_83', 'D_84', 'D_88', 'D_89', 'P_2', 'P_3', \n",
    "                'R_1', 'R_10', 'R_11', 'R_26', 'R_28', 'R_3', 'R_4', 'R_5', 'R_7', 'R_8', \n",
    "                'S_11', 'S_12', 'S_23', 'S_25', 'S_26', 'S_27', 'S_3', 'S_5', 'S_7', 'S_8', ]\n",
    "features_last = ['B_1', 'B_11', 'B_12', 'B_13', 'B_14', 'B_16', 'B_18', 'B_19', 'B_2', \n",
    "                 'B_20', 'B_21', 'B_24', 'B_27', 'B_28', 'B_29', 'B_3', 'B_30', 'B_31', \n",
    "                 'B_33', 'B_36', 'B_37', 'B_38', 'B_39', 'B_4', 'B_40', 'B_42', 'B_5', \n",
    "                 'B_8', 'B_9', 'D_102', 'D_105', 'D_106', 'D_107', 'D_108', 'D_110', \n",
    "                 'D_111', 'D_112', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', \n",
    "                 'D_119', 'D_120', 'D_121', 'D_124', 'D_126', 'D_128', 'D_129', 'D_131', \n",
    "                 'D_132', 'D_133', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', \n",
    "                 'D_143', 'D_144', 'D_145', 'D_39', 'D_41', 'D_42', 'D_43', 'D_44', 'D_45', \n",
    "                 'D_46', 'D_47', 'D_48', 'D_49', 'D_50', 'D_51', 'D_52', 'D_53', 'D_55', \n",
    "                 'D_56', 'D_59', 'D_60', 'D_62', 'D_63', 'D_64', 'D_66', 'D_68', 'D_70', \n",
    "                 'D_71', 'D_72', 'D_73', 'D_74', 'D_75', 'D_77', 'D_78', 'D_81', 'D_82', \n",
    "                 'D_83', 'D_84', 'D_88', 'D_89', 'D_91', 'D_94', 'D_96', 'P_2', 'P_3', \n",
    "                 'P_4', 'R_1', 'R_10', 'R_11', 'R_12', 'R_13', 'R_16', 'R_17', 'R_18', \n",
    "                 'R_19', 'R_25', 'R_28', 'R_3', 'R_4', 'R_5', 'R_8', 'S_11', 'S_12', \n",
    "                 'S_23', 'S_25', 'S_26', 'S_27', 'S_3', 'S_5', 'S_7', 'S_8', 'S_9', ]\n",
    "features_categorical = ['B_30_last', 'B_38_last', 'D_114_last', 'D_116_last',\n",
    "                        'D_117_last', 'D_120_last', 'D_126_last',\n",
    "                        'D_63_last', 'D_64_last', 'D_66_last', 'D_68_last']\n",
    "\n",
    "for i in ['train', 'test'] if INFERENCE else ['train']:\n",
    "    df = pd.read_parquet(f'../preprocessed_data/amex-data-integer-dtypes-parquet-format/{i}.parquet')\n",
    "    cid = pd.Categorical(df.pop('customer_ID'), ordered=True)\n",
    "    last = (cid != np.roll(cid, -1)) # mask for last statement of every customer\n",
    "    if 'target' in df.columns:\n",
    "        df.drop(columns=['target'], inplace=True)\n",
    "    print('Read', i)\n",
    "    gc.collect()\n",
    "    df_avg = (df\n",
    "              .groupby(cid)\n",
    "              .mean()[features_avg]\n",
    "              .rename(columns={f: f\"{f}_avg\" for f in features_avg})\n",
    "             )\n",
    "    print('Computed avg', i)\n",
    "    gc.collect()\n",
    "    df_max = (df\n",
    "              .groupby(cid)\n",
    "              .max()[features_max]\n",
    "              .rename(columns={f: f\"{f}_max\" for f in features_max})\n",
    "             )\n",
    "    print('Computed max', i)\n",
    "    gc.collect()\n",
    "    df_min = (df\n",
    "              .groupby(cid)\n",
    "              .min()[features_min]\n",
    "              .rename(columns={f: f\"{f}_min\" for f in features_min})\n",
    "             )\n",
    "    print('Computed min', i)\n",
    "    gc.collect()\n",
    "    df_last = (df.loc[last, features_last]\n",
    "               .rename(columns={f: f\"{f}_last\" for f in features_last})\n",
    "               .set_index(np.asarray(cid[last]))\n",
    "              )\n",
    "    df = None # we no longer need the original data\n",
    "    print('Computed last', i)\n",
    "    \n",
    "    df_categorical = df_last[features_categorical].astype(object)\n",
    "    features_not_cat = [f for f in df_last.columns if f not in features_categorical]\n",
    "    if i == 'train':\n",
    "        ohe = OneHotEncoder(drop='first', sparse=False, dtype=np.float32, handle_unknown='ignore')\n",
    "        ohe.fit(df_categorical)\n",
    "        with open(\"ohe.pickle\", 'wb') as f: pickle.dump(ohe, f)\n",
    "    df_categorical = pd.DataFrame(ohe.transform(df_categorical).astype(np.float16),\n",
    "                                  index=df_categorical.index).rename(columns=str)\n",
    "    print('Computed categorical', i)\n",
    "    \n",
    "    df = pd.concat([df_last[features_not_cat], df_categorical, df_avg, df_min, df_max], axis=1)\n",
    "    \n",
    "    # Impute missing values\n",
    "    df.fillna(value=0, inplace=True)\n",
    "    \n",
    "    del df_avg, df_max, df_min, df_last, df_categorical, cid, last, features_not_cat\n",
    "    \n",
    "    print(f\"{i} shape: {df.shape}\")\n",
    "    if i == 'train': # train\n",
    "        # Free the memory\n",
    "        df.reset_index(drop=True, inplace=True) # frees 0.2 GByte\n",
    "        df.to_feather('train_processed.ftr')\n",
    "        df = None\n",
    "        gc.collect()\n",
    "\n",
    "train = pd.read_feather('train_processed.ftr')\n",
    "!rm train_processed.ftr\n",
    "test = df\n",
    "del df, ohe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b536433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(f'C:\\\\Users\\\\Khangjrakpam Arjun\\\\OneDrive - McKinsey & Company\\\\Documents\\\\ARJUN\\\\ML\\\\COMPETITIONS\\\\Amex\\\\amex-default-prediction\\\\preprocessed_data')\n",
    "train = pd.read_pickle(\"train_agg.pkl\")\n",
    "test = pd.read_pickle(\"test_agg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc3b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.target.values\n",
    "train.drop('target',axis = 1 , inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e37ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n",
      "target shape: (458913,)\n"
     ]
    }
   ],
   "source": [
    "print(target)\n",
    "print(f\"target shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1d6eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 887)\n",
      "(924621, 887)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50ddef31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_ID', 'P_2_mean', 'P_2_std', 'P_2_min', 'P_2_max', 'P_2_last',\n",
       "       'D_39_mean', 'D_39_std', 'D_39_min', 'D_39_max',\n",
       "       ...\n",
       "       'D_120_nunique', 'D_126_count', 'D_126_last', 'D_126_nunique',\n",
       "       'D_63_count', 'D_63_last', 'D_63_nunique', 'D_64_count', 'D_64_last',\n",
       "       'D_64_nunique'],\n",
       "      dtype='object', length=887)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df16ff",
   "metadata": {
    "papermill": {
     "duration": 0.004944,
     "end_time": "2022-06-09T09:44:14.608141",
     "exception": false,
     "start_time": "2022-06-09T09:44:14.603197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The model\n",
    "\n",
    "Our model has four hidden layers, enriched by a skip connection and a Dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa83d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_START = 0.01\n",
    "\n",
    "features = [f for f in train.columns if f != 'target' and f != 'customer_ID']\n",
    "\n",
    "n_inputs=len(features)\n",
    "\"\"\"Sequential neural network with a skip connection.\n",
    "\n",
    "Returns a compiled instance of tensorflow.keras.models.Model.\n",
    "\"\"\"\n",
    "activation = 'swish'\n",
    "reg = 4e-4\n",
    "inputs = Input(shape=(n_inputs, ))\n",
    "x0 = Dense(256, kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "          activation=activation,\n",
    "         )(inputs)\n",
    "x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "          activation=activation,\n",
    "         )(x0)\n",
    "x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "          activation=activation,\n",
    "         )(x)\n",
    "x = Concatenate()([x, x0])\n",
    "x = Dropout(0.1)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Dense(16, kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "          activation=activation,\n",
    "         )(x)\n",
    "x = Dense(1, #kernel_regularizer=tf.keras.regularizers.l2(4e-4),\n",
    "          activation='sigmoid',\n",
    "         )(x)\n",
    "model = Model(inputs, x)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR_START),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy())\n",
    "\n",
    "\n",
    "#plot_model(my_model(), show_layer_names=False,  show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef86bb22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:44:14.622639Z",
     "iopub.status.busy": "2022-06-09T09:44:14.621658Z",
     "iopub.status.idle": "2022-06-09T09:44:16.186851Z",
     "shell.execute_reply": "2022-06-09T09:44:16.185892Z"
    },
    "papermill": {
     "duration": 1.575331,
     "end_time": "2022-06-09T09:44:16.189500",
     "exception": false,
     "start_time": "2022-06-09T09:44:14.614169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"dot\" with args ['-Tps', 'C:\\\\Users\\\\KHANGJ~1\\\\AppData\\\\Local\\\\Temp\\\\tmpyr2ql4pn'] returned code: 1\n",
      "\n",
      "stdout, stderr:\n",
      " b''\n",
      "b\"'C:\\\\Users\\\\Khangjrakpam' is not recognized as an internal or external command,\\r\\noperable program or batch file.\\r\\n\"\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\"dot\" with args ['-Tps', 'C:\\\\Users\\\\KHANGJ~1\\\\AppData\\\\Local\\\\Temp\\\\tmpyr2ql4pn'] returned code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     36\u001b[0m dot_img_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mKhangjrakpam Arjun\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOneDrive - McKinsey & Company\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mARJUN\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mML\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCOMPETITIONS\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mAmex\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mamex-default-prediction\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124moutput_image\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmodel_1.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_layer_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdot_img_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py:421\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    417\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    418\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    419\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 421\u001b[0m dot \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_to_dot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_layer_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_layer_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrankdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrankdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_nested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_nested\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_layer_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_layer_activations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m to_file \u001b[38;5;241m=\u001b[39m io_utils\u001b[38;5;241m.\u001b[39mpath_to_string(to_file)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py:151\u001b[0m, in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph, layer_range, show_layer_activations)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sequential\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_pydot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    152\u001b[0m   message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    153\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must install pydot (`pip install pydot`) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    154\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand install graphviz \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    155\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    156\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor plot_model/model_to_dot to work.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    157\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIPython.core.magics.namespace\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# We don't raise an exception here in order to avoid crashing notebook\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# tests where graphviz is not available.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py:51\u001b[0m, in \u001b[0;36mcheck_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m   \u001b[38;5;66;03m# Attempt to create an image of a blank graph\u001b[39;00m\n\u001b[0;32m     50\u001b[0m   \u001b[38;5;66;03m# to check the pydot/graphviz installation.\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m   \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, pydot\u001b[38;5;241m.\u001b[39mInvocationException):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py:1956\u001b[0m, in \u001b[0;36mDot.create\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1945\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with args \u001b[39m\u001b[38;5;132;01m{arguments}\u001b[39;00m\u001b[38;5;124m returned code: \u001b[39m\u001b[38;5;132;01m{code}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1946\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout, stderr:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{err}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1952\u001b[0m         err\u001b[38;5;241m=\u001b[39mstderr_data,\n\u001b[0;32m   1953\u001b[0m     )\n\u001b[0;32m   1954\u001b[0m     \u001b[38;5;28mprint\u001b[39m(message)\n\u001b[1;32m-> 1956\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m process\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, (\n\u001b[0;32m   1957\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with args \u001b[39m\u001b[38;5;132;01m{arguments}\u001b[39;00m\u001b[38;5;124m returned code: \u001b[39m\u001b[38;5;132;01m{code}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1958\u001b[0m             prog\u001b[38;5;241m=\u001b[39mprog,\n\u001b[0;32m   1959\u001b[0m             arguments\u001b[38;5;241m=\u001b[39marguments,\n\u001b[0;32m   1960\u001b[0m             code\u001b[38;5;241m=\u001b[39mprocess\u001b[38;5;241m.\u001b[39mreturncode,\n\u001b[0;32m   1961\u001b[0m         )\n\u001b[0;32m   1962\u001b[0m     )\n\u001b[0;32m   1964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stdout_data\n",
      "\u001b[1;31mAssertionError\u001b[0m: \"dot\" with args ['-Tps', 'C:\\\\Users\\\\KHANGJ~1\\\\AppData\\\\Local\\\\Temp\\\\tmpyr2ql4pn'] returned code: 1"
     ]
    }
   ],
   "source": [
    "LR_START = 0.01\n",
    "\n",
    "features = [f for f in train.columns if f != 'target' and f != 'customer_ID']\n",
    "\n",
    "def my_model(n_inputs=len(features)):\n",
    "    \"\"\"Sequential neural network with a skip connection.\n",
    "    \n",
    "    Returns a compiled instance of tensorflow.keras.models.Model.\n",
    "    \"\"\"\n",
    "    activation = 'swish'\n",
    "    reg = 4e-4\n",
    "    inputs = Input(shape=(n_inputs, ))\n",
    "    x0 = Dense(256, kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "              activation=activation,\n",
    "             )(inputs)\n",
    "    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "              activation=activation,\n",
    "             )(x0)\n",
    "    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "              activation=activation,\n",
    "             )(x)\n",
    "    x = Concatenate()([x, x0])\n",
    "    x = Dropout(0.1)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Dense(16, kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "              activation=activation,\n",
    "             )(x)\n",
    "    x = Dense(1, #kernel_regularizer=tf.keras.regularizers.l2(4e-4),\n",
    "              activation='sigmoid',\n",
    "             )(x)\n",
    "    model = Model(inputs, x)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR_START),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy())\n",
    "    return model\n",
    "\n",
    "#plot_model(my_model(), show_layer_names=False,  show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2d9a79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x2cb9bae4f40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b40ff",
   "metadata": {
    "papermill": {
     "duration": 0.00621,
     "end_time": "2022-06-09T09:44:16.202958",
     "exception": false,
     "start_time": "2022-06-09T09:44:16.196748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cross-validation\n",
    "\n",
    "We use a standard cross-validation loop. In the loop, we scale the data and train a model. We use a StratifiedKFold because the data is imbalanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7728b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T09:44:16.218012Z",
     "iopub.status.busy": "2022-06-09T09:44:16.217624Z",
     "iopub.status.idle": "2022-06-09T11:14:56.666352Z",
     "shell.execute_reply": "2022-06-09T11:14:56.665026Z"
    },
    "papermill": {
     "duration": 5440.46212,
     "end_time": "2022-06-09T11:14:56.671595",
     "exception": false,
     "start_time": "2022-06-09T09:44:16.209475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cross-validation of the classifier\n",
    "\n",
    "ONLY_FIRST_FOLD = False\n",
    "EPOCHS_EXPONENTIALDECAY = 100\n",
    "VERBOSE = 0 # set to 0 for less output, or to 2 for more output\n",
    "LR_END = 1e-5 # learning rate at the end of training\n",
    "CYCLES = 1\n",
    "EPOCHS = 200\n",
    "DIAGRAMS = True\n",
    "USE_PLATEAU = False # set to True for early stopping, or to False for exponential learning rate decay\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "def fit_model(X_tr, y_tr, X_va=None, y_va=None, fold=0, run=0):\n",
    "    \"\"\"Scale the data, fit a model, plot the training history and optionally validate the model\n",
    "    \n",
    "    Saves a trained instance of tensorflow.keras.models.Model.\n",
    "    \n",
    "    As a side effect, updates y_va_pred, history_list, y_pred_list and score_list.\n",
    "    \"\"\"\n",
    "    global y_va_pred\n",
    "    gc.collect()\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_tr = scaler.fit_transform(X_tr)\n",
    "    \n",
    "    if X_va is not None:\n",
    "        X_va = scaler.transform(X_va)\n",
    "        validation_data = (X_va, y_va)\n",
    "    else:\n",
    "        validation_data = None\n",
    "    # Define the learning rate schedule and EarlyStopping\n",
    "    if USE_PLATEAU and X_va is not None: # use early stopping\n",
    "        epochs = EPOCHS\n",
    "        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, \n",
    "                               patience=4, verbose=VERBOSE)\n",
    "        es = EarlyStopping(monitor=\"val_loss\",\n",
    "                           patience=12, \n",
    "                           verbose=1,\n",
    "                           mode=\"min\", \n",
    "                           restore_best_weights=True)\n",
    "        callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN()]\n",
    "\n",
    "    else: # use exponential learning rate decay rather than early stopping\n",
    "        epochs = EPOCHS_EXPONENTIALDECAY\n",
    "\n",
    "        def exponential_decay(epoch):\n",
    "            # v decays from e^a to 1 in every cycle\n",
    "            # w decays from 1 to 0 in every cycle\n",
    "            # epoch == 0                  -> w = 1 (first epoch of cycle)\n",
    "            # epoch == epochs_per_cycle-1 -> w = 0 (last epoch of cycle)\n",
    "            # higher a -> decay starts with a steeper decline\n",
    "            a = 3\n",
    "            epochs_per_cycle = epochs // CYCLES\n",
    "            epoch_in_cycle = epoch % epochs_per_cycle\n",
    "            if epochs_per_cycle > 1:\n",
    "                v = math.exp(a * (1 - epoch_in_cycle / (epochs_per_cycle-1)))\n",
    "                w = (v - 1) / (math.exp(a) - 1)\n",
    "            else:\n",
    "                w = 1\n",
    "            return w * LR_START + (1 - w) * LR_END\n",
    "\n",
    "        lr = LearningRateScheduler(exponential_decay, verbose=0)\n",
    "        callbacks = [lr, tf.keras.callbacks.TerminateOnNaN()]\n",
    "        \n",
    "    # Construct and compile the model\n",
    "    model = my_model(X_tr.shape[1])\n",
    "    # Train the model\n",
    "    history = model.fit(X_tr, y_tr, \n",
    "                        validation_data=validation_data, \n",
    "                        epochs=epochs,\n",
    "                        verbose=VERBOSE,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        callbacks=callbacks)\n",
    "    del X_tr, y_tr\n",
    "    with open(f\"scaler_{fold}.pickle\", 'wb') as f: pickle.dump(scaler, f)\n",
    "    model.save(f\"model_{fold}\")\n",
    "    history_list.append(history.history)\n",
    "    callbacks, es, lr, history = None, None, None, None\n",
    "    \n",
    "    if X_va is None:\n",
    "        print(f\"Training loss: {history_list[-1]['loss'][-1]:.4f}\")\n",
    "    else:\n",
    "        lastloss = f\"Training loss: {history_list[-1]['loss'][-1]:.4f} | Val loss: {history_list[-1]['val_loss'][-1]:.4f}\"\n",
    "        \n",
    "        # Inference for validation\n",
    "        y_va_pred = model.predict(X_va, batch_size=len(X_va), verbose=0).ravel()\n",
    "        \n",
    "        # Evaluation: Execution time, loss and metrics\n",
    "        score = amex_metric(y_va, y_va_pred)\n",
    "        print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {run}.{fold} | {str(datetime.datetime.now() - start_time)[-12:-7]}\"\n",
    "              f\" | {len(history_list[-1]['loss']):3} ep\"\n",
    "              f\" | {lastloss} | Score: {score:.5f}{Style.RESET_ALL}\")\n",
    "        score_list.append(score)\n",
    "        \n",
    "        if DIAGRAMS and fold == 0 and run == 0:\n",
    "            # Plot training history\n",
    "            plot_history(history_list[-1], \n",
    "                         title=f\"Learning curve\",\n",
    "                         plot_lr=True)\n",
    "\n",
    "            # Plot prediction histogram\n",
    "            plt.figure(figsize=(16, 5))\n",
    "            plt.hist(y_va_pred[y_va == 0], bins=np.linspace(0, 1, 21),\n",
    "                     alpha=0.5, density=True)\n",
    "            plt.hist(y_va_pred[y_va == 1], bins=np.linspace(0, 1, 21),\n",
    "                     alpha=0.5, density=True)\n",
    "            plt.xlabel('y_pred')\n",
    "            plt.ylabel('density')\n",
    "            plt.title('OOF Prediction Histogram')\n",
    "            plt.show()\n",
    "\n",
    "        # Scale and predict\n",
    "        y_pred_list.append(model.predict(scaler.transform(test), batch_size=128*1024, verbose=0).ravel())\n",
    "        with np.printoptions(linewidth=150, precision=2, suppress=True):\n",
    "            print(f\"Test pred {fold}\", y_pred_list[-1])\n",
    "\n",
    "\n",
    "print(f\"{len(features)} features\")\n",
    "history_list = []\n",
    "score_list = []\n",
    "y_pred_list = []\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(train, target)):\n",
    "    y_va = target[idx_va]\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    fit_model(train.iloc[idx_tr][features], target[idx_tr], \n",
    "              train.iloc[idx_va][features], y_va, fold=fold)\n",
    "    if ONLY_FIRST_FOLD: break # we only need the first fold\n",
    "\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}OOF Score:                       {np.mean(score_list):.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8760989",
   "metadata": {
    "papermill": {
     "duration": 0.010888,
     "end_time": "2022-06-09T11:14:56.693096",
     "exception": false,
     "start_time": "2022-06-09T11:14:56.682208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Understanding the competition metric\n",
    "\n",
    "Assuming you know the [ROC (receiver operating characteristic) curve](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics), the competition metric has a simple graphical explanation. The following diagram shows the ROC curve for the last fold in dark red. The area under the curve (AUC) is filled with light red. The green line corresponds to 4 % of all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af2f676",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-09T11:14:56.713350Z",
     "iopub.status.busy": "2022-06-09T11:14:56.712891Z",
     "iopub.status.idle": "2022-06-09T11:14:57.050280Z",
     "shell.execute_reply": "2022-06-09T11:14:57.049197Z"
    },
    "papermill": {
     "duration": 0.35163,
     "end_time": "2022-06-09T11:14:57.053394",
     "exception": false,
     "start_time": "2022-06-09T11:14:56.701764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g, d, amex = amex_metric(y_va, y_va_pred, return_components=True)\n",
    "total_positive = (y_va == 1).sum()\n",
    "total_negative = (y_va == 0).sum() * 20\n",
    "fourpercent = int(0.04 * (total_positive + total_negative))\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "fpr, tpr, _ = roc_curve(y_va, y_va_pred)\n",
    "plt.plot(fpr, tpr, color='#c00000', lw=3) # curve\n",
    "plt.fill_between(fpr, tpr, color='#ffc0c0') # area under the curve\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\") # diagonal\n",
    "plt.plot([fourpercent / total_negative, 0], [0, fourpercent / total_positive],\n",
    "         color=\"green\", lw=3, linestyle=\"-\") # four percent line\n",
    "four_percent_index = np.argmax((fpr * total_negative + tpr * total_positive >= fourpercent))\n",
    "plt.scatter([fpr[four_percent_index]],\n",
    "            [tpr[four_percent_index]], \n",
    "            s=100) # intersection of roc curve with four percent line\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"Receiver operating characteristic\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Area under the curve (AUC):         {roc_auc_score(y_va, y_va_pred):.5f}\")\n",
    "print(f\"2*AUC-1:                            {2 * roc_auc_score(y_va, y_va_pred) - 1:.5f}\")\n",
    "print(f\"Normalized Gini coefficient:        {g:.5f} (same as 2*AUC-1)\")\n",
    "print()\n",
    "print(f\"Positive samples in validation set: {total_positive:7}\")\n",
    "#print(f\"Negative samples in validation set: {total_negative // 20:7}\")\n",
    "print(f\"Negative samples weighted:          {total_negative:7} (unweighted: {total_negative // 20})\")\n",
    "print(f\"Total samples weighted:             {total_positive + total_negative:7}\")\n",
    "print(f\"4 % of Total samples weighted:      {fourpercent:7}\")\n",
    "print(f\"True positives at this threshold:   {int(tpr[four_percent_index] * total_positive):7}\")\n",
    "print(f\"False positives at this threshold:  {int(fpr[four_percent_index] * total_negative):7}\")\n",
    "print(f\"Default rate captured at 4%:        {d:7.5f} (= {int(tpr[four_percent_index] * total_positive)} / {total_positive})\")\n",
    "print()\n",
    "print(f\"Competition score:                  {amex:7.5f} (= ({g:7.5f} + {d:7.5f}) / 2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09606f",
   "metadata": {
    "papermill": {
     "duration": 0.009926,
     "end_time": "2022-06-09T11:14:57.073834",
     "exception": false,
     "start_time": "2022-06-09T11:14:57.063908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The competition metric has two components: the normalized Gini coefficient and the default rate captured at 4 %:\n",
    "- The *normalized Gini coefficient* is simply a scaled AUC: AUC is the light red area under the curve and can be between 0 and 1. The normalized Gini coefficient is equal to 2\\*AUC-1 and is always between -1 and 1. The larger the light red area, the better is the score.\n",
    "- The *default rate captured at 4 %* is the true positive rate (recall) for a threshold set at 4 % of the total (weighted) sample count. It corresponds to the y coordinate of the intersection between the green line and the red roc curve (marked with a green dot) and is always between 0 and 1. The higher the intersection point, the better is the score.\n",
    "\n",
    "The competition metric is the average of these two components. In other words: They want us to simultaneously optimize for a large red area under the curve and a high intersection point with the green line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfda68d",
   "metadata": {
    "papermill": {
     "duration": 0.009282,
     "end_time": "2022-06-09T11:14:57.092786",
     "exception": false,
     "start_time": "2022-06-09T11:14:57.083504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "We submit the mean of the ten predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bf9c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T11:14:57.113795Z",
     "iopub.status.busy": "2022-06-09T11:14:57.113410Z",
     "iopub.status.idle": "2022-06-09T11:15:00.297608Z",
     "shell.execute_reply": "2022-06-09T11:15:00.296879Z"
    },
    "papermill": {
     "duration": 3.197232,
     "end_time": "2022-06-09T11:15:00.299580",
     "exception": false,
     "start_time": "2022-06-09T11:14:57.102348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensemble the predictions of all folds\n",
    "sub = pd.DataFrame({'customer_ID': test.index,\n",
    "                    'prediction': np.mean(y_pred_list, axis=0)})\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7c72f",
   "metadata": {
    "papermill": {
     "duration": 0.009457,
     "end_time": "2022-06-09T11:15:00.318495",
     "exception": false,
     "start_time": "2022-06-09T11:15:00.309038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As a plausibility test, we plot a histogram of the predictions. The histogram should resemble the OOF histogram (see above), and the majority of the predictions should be near 0 (because the classes are imbalanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca5c7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-09T11:15:00.340924Z",
     "iopub.status.busy": "2022-06-09T11:15:00.339957Z",
     "iopub.status.idle": "2022-06-09T11:15:00.636195Z",
     "shell.execute_reply": "2022-06-09T11:15:00.635436Z"
    },
    "papermill": {
     "duration": 0.30992,
     "end_time": "2022-06-09T11:15:00.638075",
     "exception": false,
     "start_time": "2022-06-09T11:15:00.328155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.hist(sub.prediction, bins=np.linspace(0, 1, 21), density=True)\n",
    "plt.title(\"Plausibility check\", fontsize=20)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee113eb",
   "metadata": {
    "papermill": {
     "duration": 0.009588,
     "end_time": "2022-06-09T11:15:00.657562",
     "exception": false,
     "start_time": "2022-06-09T11:15:00.647974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5861.253701,
   "end_time": "2022-06-09T11:15:04.248758",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-09T09:37:22.995057",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
